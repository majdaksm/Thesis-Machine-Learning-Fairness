{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import imblearn\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the sensitive attribute 'Age Group' or 'sex '###\n",
    "sen_att = 'Age Group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     stat_check_acc  duration_month  credit_history  purpose  credit_amount  \\\n",
      "0                 1               6               5        4           1169   \n",
      "1                 2              48               3        4           5951   \n",
      "2                 4              12               5        7           2096   \n",
      "3                 1              42               3        3           7882   \n",
      "4                 1              24               4        1           4870   \n",
      "..              ...             ...             ...      ...            ...   \n",
      "995               4              12               3        3           1736   \n",
      "996               1              30               3        2           3857   \n",
      "997               4              12               3        4            804   \n",
      "998               1              45               3        4           1845   \n",
      "999               2              45               5        2           4576   \n",
      "\n",
      "     Age Group  savings_bonds  employment_since  installment_in_percent  sex  \\\n",
      "0            1              5                 5                       4    0   \n",
      "1            0              1                 3                       2    1   \n",
      "2            0              1                 4                       2    0   \n",
      "3            0              1                 4                       2    0   \n",
      "4            1              1                 3                       3    0   \n",
      "..         ...            ...               ...                     ...  ...   \n",
      "995          0              1                 4                       3    1   \n",
      "996          0              1                 3                       4    0   \n",
      "997          0              1                 5                       4    0   \n",
      "998          0              1                 3                       4    0   \n",
      "999          0              2                 1                       3    0   \n",
      "\n",
      "     debtors_guarant  residence_since  property  other_installment_plans  \\\n",
      "0                  1                4         1                        3   \n",
      "1                  1                2         1                        3   \n",
      "2                  1                3         1                        3   \n",
      "3                  3                4         2                        3   \n",
      "4                  1                4         4                        3   \n",
      "..               ...              ...       ...                      ...   \n",
      "995                1                4         1                        3   \n",
      "996                1                4         2                        3   \n",
      "997                1                4         3                        3   \n",
      "998                1                4         4                        3   \n",
      "999                1                4         3                        3   \n",
      "\n",
      "     housing  nr_credits  job  nr_dependants  phone  approval  \n",
      "0          2           2    3              1      2         1  \n",
      "1          2           1    3              1      1         0  \n",
      "2          2           1    2              2      1         1  \n",
      "3          3           1    3              2      1         1  \n",
      "4          3           2    3              2      1         0  \n",
      "..       ...         ...  ...            ...    ...       ...  \n",
      "995        2           1    2              1      1         1  \n",
      "996        2           1    4              1      2         1  \n",
      "997        2           1    3              1      1         1  \n",
      "998        3           1    3              1      2         0  \n",
      "999        2           1    3              1      1         1  \n",
      "\n",
      "[1000 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "german_data = pd.read_csv('german_data.csv')\n",
    "\n",
    "\n",
    "print(german_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = german_data.loc[:, german_data.columns != 'approval']\n",
    "y = german_data.loc[:, german_data.columns == 'approval']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify = y, random_state=0)\n",
    "\n",
    "### remove the sensitive attributes for execution but store them for metrics later ###\n",
    "\n",
    "X_test_sen = X_test.loc[:,X_test.columns == sen_att]\n",
    "X_test = X_test.loc[:, X_test.columns != sen_att]\n",
    "\n",
    "X_train = X_train.loc[:, X_train.columns != sen_att]\n",
    "\n",
    "### apply SMOTE to the training set ###\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "os_data_X, os_data_y=os.fit_sample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['approval'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.71      0.63        75\n",
      "           1       0.86      0.77      0.81       175\n",
      "\n",
      "    accuracy                           0.75       250\n",
      "   macro avg       0.71      0.74      0.72       250\n",
      "weighted avg       0.77      0.75      0.76       250\n",
      "\n",
      "[[ 53  22]\n",
      " [ 40 135]] 0.752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "\n",
    "\n",
    "os_data_y_2 =os_data_y.to_numpy()\n",
    "os_data_y_2 =os_data_y_2.ravel()\n",
    "\n",
    "logit = LogisticRegression(penalty='l2', solver = 'liblinear', max_iter = 5000)\n",
    "#logit = LogisticRegression()\n",
    "logit.fit(os_data_X, os_data_y_2)\n",
    "\n",
    "\n",
    "y_pred =  logit.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "accuracy_score = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "print(matrix, accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### identify privileged and unprivileged groups ### \n",
    "privileged_groups = [{sen_att: 0}]\n",
    "unprivileged_groups = [{sen_att: 1}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## #adjust  predictions for use AIF360 Library ###\n",
    "\n",
    "fair_test_df = pd.concat([X_test, X_test_sen], axis=1, join=\"inner\")\n",
    "fair_test_df = pd.concat([fair_test_df, y_test], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.7390\n",
      "Statistical parity difference = 0.0324\n",
      "Disparate impact = 1.0519\n",
      "Average odds difference = -0.0470\n",
      "Equal opportunity difference = 0.1130\n"
     ]
    }
   ],
   "source": [
    "# Metrics function\n",
    "from collections import OrderedDict\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "dataset = StandardDataset(fair_test_df, \n",
    "                          label_name='approval', \n",
    "                          favorable_classes=[1], \n",
    "                          protected_attribute_names=[sen_att], \n",
    "                          privileged_classes=[[0]])\n",
    "\n",
    "def fair_metrics(dataset, y_pred, disp = True):\n",
    "    dataset_pred =dataset.copy()\n",
    "    dataset_pred.labels = y_pred\n",
    "        \n",
    "    attr = dataset_pred.protected_attribute_names[0]\n",
    "    \n",
    "    idx = dataset_pred.protected_attribute_names.index(attr)\n",
    "    privileged_groups =  [{attr:dataset_pred.privileged_protected_attributes[idx][0]}] \n",
    "    unprivileged_groups = [{attr:dataset_pred.unprivileged_protected_attributes[idx][0]}] \n",
    "\n",
    "    classified_metric_pred = ClassificationMetric(dataset, dataset_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "    metric_pred = BinaryLabelDatasetMetric(dataset_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "    metrics = OrderedDict()\n",
    "    metrics[\"Balanced accuracy\"] = 0.5*(classified_metric_pred.true_positive_rate()+\n",
    "                                             classified_metric_pred.true_negative_rate())\n",
    "    metrics[\"Statistical parity difference\"] = classified_metric_pred.statistical_parity_difference()\n",
    "    metrics[\"Disparate impact\"] = classified_metric_pred.disparate_impact()\n",
    "    metrics[\"Average odds difference\"] = classified_metric_pred.average_odds_difference()\n",
    "    metrics[\"Equal opportunity difference\"] = classified_metric_pred.equal_opportunity_difference()\n",
    "        \n",
    "    if disp:\n",
    "        for k in metrics:\n",
    "            print(\"%s = %.4f\" % (k, metrics[k]))\n",
    "\n",
    "\n",
    "fair_metrics(dataset, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
