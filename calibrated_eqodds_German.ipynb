{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aif360\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.metrics import utils\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets.multiclass_label_dataset import MulticlassLabelDataset\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "                import load_preproc_data_adult, load_preproc_data_compas\n",
    "\n",
    "\n",
    "import sklearn \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import imblearn\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import math \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     stat_check_acc  duration_month  credit_history  purpose  credit_amount  \\\n",
      "0                 1               6               5        4           1169   \n",
      "1                 2              48               3        4           5951   \n",
      "2                 4              12               5        7           2096   \n",
      "3                 1              42               3        3           7882   \n",
      "4                 1              24               4        1           4870   \n",
      "..              ...             ...             ...      ...            ...   \n",
      "995               4              12               3        3           1736   \n",
      "996               1              30               3        2           3857   \n",
      "997               4              12               3        4            804   \n",
      "998               1              45               3        4           1845   \n",
      "999               2              45               5        2           4576   \n",
      "\n",
      "     Age Group  savings_bonds  employment_since  installment_in_percent  sex  \\\n",
      "0            1              5                 5                       4    0   \n",
      "1            0              1                 3                       2    1   \n",
      "2            0              1                 4                       2    0   \n",
      "3            0              1                 4                       2    0   \n",
      "4            1              1                 3                       3    0   \n",
      "..         ...            ...               ...                     ...  ...   \n",
      "995          0              1                 4                       3    1   \n",
      "996          0              1                 3                       4    0   \n",
      "997          0              1                 5                       4    0   \n",
      "998          0              1                 3                       4    0   \n",
      "999          0              2                 1                       3    0   \n",
      "\n",
      "     debtors_guarant  residence_since  property  other_installment_plans  \\\n",
      "0                  1                4         1                        3   \n",
      "1                  1                2         1                        3   \n",
      "2                  1                3         1                        3   \n",
      "3                  3                4         2                        3   \n",
      "4                  1                4         4                        3   \n",
      "..               ...              ...       ...                      ...   \n",
      "995                1                4         1                        3   \n",
      "996                1                4         2                        3   \n",
      "997                1                4         3                        3   \n",
      "998                1                4         4                        3   \n",
      "999                1                4         3                        3   \n",
      "\n",
      "     housing  nr_credits  job  nr_dependants  phone  approval  \n",
      "0          2           2    3              1      2         1  \n",
      "1          2           1    3              1      1         0  \n",
      "2          2           1    2              2      1         1  \n",
      "3          3           1    3              2      1         1  \n",
      "4          3           2    3              2      1         0  \n",
      "..       ...         ...  ...            ...    ...       ...  \n",
      "995        2           1    2              1      1         1  \n",
      "996        2           1    4              1      2         1  \n",
      "997        2           1    3              1      1         1  \n",
      "998        3           1    3              1      2         0  \n",
      "999        2           1    3              1      1         1  \n",
      "\n",
      "[1000 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "german_data = pd.read_csv('german_data.csv')\n",
    "print(german_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set sensitive attribute equal to 'sex' or 'Age Group' ###\n",
    "\n",
    "sen_att = 'Age Group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data in a test val and train set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = german_data.loc[:, german_data.columns != 'approval']\n",
    "y = german_data.loc[:, german_data.columns == 'approval']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, stratify = y_train, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply SMOTE to the trainingset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns\n",
    "X_train_balanced, y_train_balanced=os.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### combine the sets together to make them compatible with the AIF360 library ### \n",
    "balanced_german_train_df = pd.concat([X_train_balanced, y_train_balanced], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_val_df = pd.concat([X_val, y_val], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_test_df = pd.concat([X_test, y_test], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "dataset_orig_train = aif360.datasets.BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=balanced_german_train_df,\n",
    "    label_names=['approval'],\n",
    "    protected_attribute_names=[sen_att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "dataset_orig_valid = aif360.datasets.BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=german_val_df,\n",
    "    label_names=['approval'],\n",
    "    protected_attribute_names=[sen_att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "dataset_orig_test = aif360.datasets.BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=german_test_df,\n",
    "    label_names=['approval'],\n",
    "    protected_attribute_names=[sen_att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "dataset_orig = aif360.datasets.BinaryLabelDataset(\n",
    "    favorable_label=1,\n",
    "    unfavorable_label=0,\n",
    "    df=german_data,\n",
    "    label_names=['approval'],\n",
    "    protected_attribute_names=[sen_att])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{sen_att: 0}]\n",
    "unprivileged_groups = [{sen_att: 1}]\n",
    "cost_constraint = \"fnr\"\n",
    "randseed = 12345679 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING THE LOGISTIC REGRESSION ###\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Placeholder for predicted and transformed datasets\n",
    "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "\n",
    "dataset_new_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_new_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "\n",
    "# Logistic regression classifier and predictions for training data\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "\n",
    "fav_idx = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "y_train_pred_prob = lmod.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "# Prediction probs for validation and testing data\n",
    "X_valid = scale_orig.transform(dataset_orig_valid.features)\n",
    "y_valid_pred_prob = lmod.predict_proba(X_valid)[:,fav_idx]\n",
    "\n",
    "X_test = scale_orig.transform(dataset_orig_test.features)\n",
    "y_test_pred_prob = lmod.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "class_thresh = 0.5\n",
    "dataset_orig_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_orig_valid_pred.scores = y_valid_pred_prob.reshape(-1,1)\n",
    "dataset_orig_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "y_train_pred = np.zeros_like(dataset_orig_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_orig_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_orig_train_pred.unfavorable_label\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "y_valid_pred = np.zeros_like(dataset_orig_valid_pred.labels)\n",
    "y_valid_pred[y_valid_pred_prob >= class_thresh] = dataset_orig_valid_pred.favorable_label\n",
    "y_valid_pred[~(y_valid_pred_prob >= class_thresh)] = dataset_orig_valid_pred.unfavorable_label\n",
    "dataset_orig_valid_pred.labels = y_valid_pred\n",
    "    \n",
    "y_test_pred = np.zeros_like(dataset_orig_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_orig_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_orig_test_pred.unfavorable_label\n",
    "dataset_orig_test_pred.labels = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fairness Metrics function ###\n",
    "from collections import OrderedDict\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "def compute_metrics(dataset_true, dataset_pred, \n",
    "                    unprivileged_groups, privileged_groups,\n",
    "                    disp = True):\n",
    "    \"\"\" Compute the key metrics \"\"\"\n",
    "    classified_metric_pred = ClassificationMetric(dataset_true,\n",
    "                                                 dataset_pred, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    metrics = OrderedDict()\n",
    "    metrics[\"Balanced accuracy\"] = 0.5*(classified_metric_pred.true_positive_rate()+\n",
    "                                             classified_metric_pred.true_negative_rate())\n",
    "    metrics[\"Statistical parity difference\"] = classified_metric_pred.statistical_parity_difference()\n",
    "    metrics[\"Disparate impact\"] = classified_metric_pred.disparate_impact()\n",
    "    metrics[\"Average odds difference\"] = classified_metric_pred.average_odds_difference()\n",
    "    metrics[\"Equal opportunity difference\"] = classified_metric_pred.equal_opportunity_difference()\n",
    "    \n",
    "    if disp:\n",
    "        for k in metrics:\n",
    "            print(\"%s = %.4f\" % (k, metrics[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perform Calibrated Equality of Odds Pleiss et al., 2017 ###\n",
    "\n",
    "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Learn qualize odds and apply to create a new dataset ###\n",
    "cpp = CalibratedEqOddsPostprocessing(privileged_groups = privileged_groups,\n",
    "                                     unprivileged_groups = unprivileged_groups,\n",
    "                                     cost_constraint=cost_constraint,\n",
    "                                     seed=randseed)\n",
    "cpp = cpp.fit(dataset_orig_valid, dataset_orig_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform test data using the post processing algorithm\n",
    "\n",
    "dataset_transf_test_pred = cpp.predict(dataset_orig_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.7083\n",
      "Statistical parity difference = 0.3125\n",
      "Disparate impact = 1.4545\n",
      "Average odds difference = 0.3959\n",
      "Equal opportunity difference = 0.1736\n"
     ]
    }
   ],
   "source": [
    " ### fairness metrics extraction ### \n",
    "    \n",
    "metric_test_aft = compute_metrics(dataset_orig_test, dataset_transf_test_pred, \n",
    "                                  unprivileged_groups, privileged_groups,\n",
    "                                  disp = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34  26]\n",
      " [ 21 119]] 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.57      0.59        60\n",
      "         1.0       0.82      0.85      0.84       140\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.72      0.71      0.71       200\n",
      "weighted avg       0.76      0.77      0.76       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### extract test labels and prediction label for traditional model evaluation ###\n",
    "\n",
    "y_test = dataset_orig_test.labels.ravel()\n",
    "y_pred = dataset_transf_test_pred.labels.ravel()\n",
    "\n",
    "### obtain performance metrics ###\n",
    "\n",
    "matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "accuracy_score = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "print(matrix, accuracy_score)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
